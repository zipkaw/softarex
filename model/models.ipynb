{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import catboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test.csv.zip\n",
      "../data/sampleSubmission.csv\n",
      "../data/train.csv.zip\n",
      "../data/web_sub.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('../data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  ...   \n",
      "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2  ...  \\\n",
      "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1  ...   \n",
      "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2  ...   \n",
      "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4  ...   \n",
      "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2  ...   \n",
      "\n",
      "   P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
      "0  3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
      "1  3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
      "2  3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
      "3  7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
      "4  3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "trainval_filename = '../data/train.csv.zip'\n",
    "test_filename = '../data/test.csv.zip'\n",
    "df_trainval = pd.read_csv(trainval_filename)\n",
    "df_test = pd.read_csv(test_filename)\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1,test_size=0.1)\n",
    "print(df_trainval.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainval = df_trainval['revenue']\n",
    "del df_trainval['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   City Group Type\n",
      "0  Big Cities   IL\n",
      "1  Big Cities   FC\n",
      "2       Other   IL\n",
      "3       Other   IL\n",
      "4       Other   IL\n"
     ]
    }
   ],
   "source": [
    "print(df_trainval[['City Group','Type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Open Date  City  City Group  Type  P1   P2   P3   P4  P5  ...  P32   \n",
      "0   0 1999-07-17    60           1     1   4  5.0  4.0  4.0   2  ...    4  \\\n",
      "1   1 2008-02-14     4           1     0   4  5.0  4.0  4.0   1  ...    0   \n",
      "2   2 2013-03-09    14           0     1   2  4.0  2.0  5.0   2  ...    0   \n",
      "3   3 2012-02-02    52           0     1   6  4.5  6.0  6.0   4  ...   10   \n",
      "4   4 2009-05-09    21           0     1   3  4.0  3.0  4.0   2  ...    3   \n",
      "\n",
      "   P33  P34  P35  P36  P37  Year  Month  Day  week_name  \n",
      "0    5    5    4    3    4  1999      7   17   Saturday  \n",
      "1    0    0    0    0    0  2008      2   14   Thursday  \n",
      "2    0    0    0    0    0  2013      3    9   Saturday  \n",
      "3    6   18   12   12    6  2012      2    2   Thursday  \n",
      "4    2    3    4    3    3  2009      5    9   Saturday  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "   Id  Open Date  City  City Group  Type  P1   P2   P3   P4  P5  ...  P32   \n",
      "0   0 1999-07-17    60           1     1   4  5.0  4.0  4.0   2  ...    4  \\\n",
      "1   1 2008-02-14     4           1     0   4  5.0  4.0  4.0   1  ...    0   \n",
      "2   2 2013-03-09    14           0     1   2  4.0  2.0  5.0   2  ...    0   \n",
      "3   3 2012-02-02    52           0     1   6  4.5  6.0  6.0   4  ...   10   \n",
      "4   4 2009-05-09    21           0     1   3  4.0  3.0  4.0   2  ...    3   \n",
      "\n",
      "   P33  P34  P35  P36  P37  Year  Month  Day  week_name  \n",
      "0    5    5    4    3    4  1999      7   17          6  \n",
      "1    0    0    0    0    0  2008      2   14          4  \n",
      "2    0    0    0    0    0  2013      3    9          6  \n",
      "3    6   18   12   12    6  2012      2    2          4  \n",
      "4    2    3    4    3    3  2009      5    9          6  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([df_trainval,df_test],axis=0)\n",
    "df_all['Open Date'] = pd.to_datetime(df_all[\"Open Date\"])\n",
    "df_all['Year'] = df_all['Open Date'].apply(lambda x:x.year)\n",
    "df_all['Month'] = df_all['Open Date'].apply(lambda x:x.month)\n",
    "df_all['Day'] = df_all['Open Date'].apply(lambda x:x.day)\n",
    "df_all['week_name'] = df_all['Open Date'].apply(lambda x:x.day_name())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['City'] = le.fit_transform(df_all['City'])\n",
    "df_all['City Group'] = df_all['City Group'].map({'Other':0,'Big Cities':1}) #There are only 'Other' or 'Big city'\n",
    "df_all[\"Type\"] = df_all[\"Type\"].map({\"FC\":0, \"IL\":1, \"DT\":2, \"MB\":3}) #There are only 'FC' or 'IL' or 'DT' or 'MB'\n",
    "print(df_all.head())\n",
    "df_all[\"week_name\"] = df_all[\"week_name\"].map({\"Sunday\":0, \"Monday\":1, \"Tuesday\":2, \"Wednesday\":3,\"Thursday\":4,\"Friday\":5,\"Saturday\":6}) #There are only 'FC' or 'IL' or 'DT' or 'MB'\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval = df_all.iloc[:df_trainval.shape[0]]\n",
    "df_test = df_all.iloc[df_trainval.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_col = [col for col in df_trainval.columns if col not in ['Id','Open Date']]\n",
    "df_trainval = df_trainval[df_train_col]\n",
    "df_test = df_test[df_train_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class Model1KNN:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        #params = {\"kernel\":['rbf'],\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n",
    "        self.model = KNeighborsRegressor(n_neighbors=5,\n",
    "                                         #weights='uniform'\n",
    "                                        )\n",
    "        \n",
    "        self.model.fit(tr_x,tr_y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "class Model1NN:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "    '''\n",
    "    def weight_variable(self,shape,name):\n",
    "        initial =tf.truncated_normal(shape,stddev=0.1)\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    def bias_variable(self,shape,name):\n",
    "        initial = tf.constant(0.1,shape=shape)\n",
    "        return tf.Variable(initial, name=name)\n",
    "    '''     \n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        \n",
    "        batch_size = 128\n",
    "        epochs = 10000\n",
    "        \n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        va_x = self.scaler.transform(va_x)\n",
    "        \n",
    "        early_stopping =  EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            min_delta=0.0,\n",
    "                            patience=20,\n",
    "        )\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', input_shape=(tr_x.shape[1],)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(32, activation='sigmoid'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', #'categorical_crossentropy',#categorical_crossentropy\n",
    "                      optimizer='adam')\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(va_x, va_y),\n",
    "                            callbacks=[early_stopping])\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x).argmax(axis=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "class Model1lgb:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        lgb_params = {'objective': 'rmse',\n",
    "                  'random_state': 10,\n",
    "                  'metric': 'rmse'}\n",
    "        lgb_train = lgb.Dataset(tr_x, label=tr_y)\n",
    "        lgb_eval = lgb.Dataset(va_x, label=va_y,reference=lgb_train)\n",
    "        self.model = lgb.train(lgb_params, lgb_train, valid_sets=lgb_eval, num_boost_round=10000,early_stopping_rounds=50)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x,num_iteration=self.model.best_iteration)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "class Model1RF:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        self.model = RandomForestRegressor(\n",
    "            max_depth=5,\n",
    "            n_estimators=100,\n",
    "            random_state=10,\n",
    "        )\n",
    "        self.model.fit(tr_x,tr_y)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class Model2Linear:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=10)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_predict(model, train_x, train_y):\n",
    "    preds = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=10)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    return pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, train_x, test_x):\n",
    "    return model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a = Model1KNN()\n",
    "model_1b = Model1NN()\n",
    "model_1c = Model1RF()\n",
    "model_1d = Model1lgb()\n",
    "model2 = Model2Linear()\n",
    "models = {\n",
    "    'KNeighbors':model_1a,\n",
    "    'NeuralNetwork':model_1b,\n",
    "    'RandomForest':model_1c, \n",
    "    'LightGBM': model_1d,\n",
    "    'Linear':model2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4780794.8 2022220.6 3853535.2 ... 5085440.4 4693501.6 6261865.6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_train_1a =  train_model_and_predict(model_1a, df_trainval, y_trainval)\n",
    "pred_test_1a =  predict(model_1a, df_trainval, df_test)\n",
    "print(pred_test_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 23:36:47.935699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 23:36:48.150827: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 594ms/step - loss: 25176987140096.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 25176987140096.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25176991334400.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 25176987140096.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25176987140096.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25176987140096.0000 - val_loss: 30048971128832.0000\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25176991334400.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 25176982945792.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25176987140096.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 25176985042944.0000 - val_loss: 30048969031680.0000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28500874493952.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28500868202496.0000 - val_loss: 20122848722944.0000\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 28500870299648.0000 - val_loss: 20122848722944.0000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 27211824365568.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211815976960.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211818074112.0000 - val_loss: 24027930296320.0000\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27211820171264.0000 - val_loss: 24027930296320.0000\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784859561984.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 24784859561984.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784859561984.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784853270528.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 24784853270528.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 24784857464832.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784853270528.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24784853270528.0000 - val_loss: 31380182401024.0000\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24784853270528.0000 - val_loss: 31380182401024.0000\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "3125/3125 [==============================] - 2s 658us/step\n"
     ]
    }
   ],
   "source": [
    "pred_train_1b = train_model_and_predict(model_1b, df_trainval, y_trainval)\n",
    "pred_test_1b = predict(model_1b, df_trainval, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3552793.9669335  3418135.25837476 4024787.2315632  ... 5047910.08258673\n",
      " 3699354.76512655 5068153.08446716]\n"
     ]
    }
   ],
   "source": [
    "pred_train_1c =  train_model_and_predict(model_1c, df_trainval, y_trainval)\n",
    "pred_test_1c = predict(model_1c, df_trainval, df_test)\n",
    "print(pred_test_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 332\n",
      "[LightGBM] [Info] Number of data points in the train set: 102, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4366984.794118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's rmse: 2.79678e+06\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's rmse: 2.76872e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's rmse: 2.73529e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's rmse: 2.70805e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's rmse: 2.69223e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's rmse: 2.66282e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's rmse: 2.64506e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's rmse: 2.63429e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's rmse: 2.62025e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's rmse: 2.60388e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's rmse: 2.59307e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's rmse: 2.58971e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's rmse: 2.58136e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's rmse: 2.56908e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's rmse: 2.55642e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's rmse: 2.55879e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's rmse: 2.56362e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's rmse: 2.5527e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's rmse: 2.55099e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's rmse: 2.54568e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's rmse: 2.53497e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's rmse: 2.5304e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's rmse: 2.53601e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's rmse: 2.53057e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's rmse: 2.52284e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's rmse: 2.52129e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's rmse: 2.52872e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's rmse: 2.52535e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's rmse: 2.52027e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's rmse: 2.51222e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's rmse: 2.51118e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's rmse: 2.5177e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's rmse: 2.51623e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's rmse: 2.51579e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's rmse: 2.52042e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's rmse: 2.51838e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's rmse: 2.51254e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's rmse: 2.51976e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's rmse: 2.52889e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's rmse: 2.52601e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's rmse: 2.5242e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's rmse: 2.52016e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's rmse: 2.52716e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's rmse: 2.53412e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's rmse: 2.53434e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's rmse: 2.54195e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's rmse: 2.542e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's rmse: 2.53337e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's rmse: 2.54936e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's rmse: 2.55272e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's rmse: 2.54903e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's rmse: 2.55521e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's rmse: 2.55677e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's rmse: 2.561e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's rmse: 2.55315e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's rmse: 2.56211e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's rmse: 2.56229e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's rmse: 2.56264e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's rmse: 2.57749e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's rmse: 2.5834e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's rmse: 2.58453e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's rmse: 2.58225e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's rmse: 2.58919e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's rmse: 2.5937e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's rmse: 2.59809e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's rmse: 2.59875e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's rmse: 2.60528e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's rmse: 2.60644e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's rmse: 2.59952e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's rmse: 2.59707e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's rmse: 2.59824e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's rmse: 2.59854e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's rmse: 2.60466e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's rmse: 2.60602e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's rmse: 2.6051e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's rmse: 2.60912e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's rmse: 2.61819e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's rmse: 2.624e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's rmse: 2.62547e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's rmse: 2.62412e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's rmse: 2.62557e+06\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's rmse: 2.51118e+06\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 324\n",
      "[LightGBM] [Info] Number of data points in the train set: 103, number of used features: 43\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4568715.485437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's rmse: 1.83991e+06\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's rmse: 1.82364e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's rmse: 1.80935e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's rmse: 1.8026e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's rmse: 1.80493e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's rmse: 1.813e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's rmse: 1.81171e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's rmse: 1.81793e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's rmse: 1.81823e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's rmse: 1.81758e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's rmse: 1.82978e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's rmse: 1.83323e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's rmse: 1.84183e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's rmse: 1.856e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's rmse: 1.86931e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's rmse: 1.87993e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's rmse: 1.89487e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's rmse: 1.89226e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's rmse: 1.90366e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's rmse: 1.93049e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's rmse: 1.92798e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's rmse: 1.94203e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's rmse: 1.95225e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's rmse: 1.95229e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's rmse: 1.95937e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's rmse: 1.96058e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's rmse: 1.97278e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's rmse: 1.96616e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's rmse: 1.97234e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's rmse: 1.97848e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's rmse: 1.98041e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's rmse: 1.99228e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's rmse: 1.99736e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's rmse: 2.00597e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's rmse: 2.01788e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's rmse: 2.02128e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's rmse: 2.03129e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's rmse: 2.03565e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's rmse: 2.04511e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's rmse: 2.03958e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's rmse: 2.05442e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's rmse: 2.07074e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's rmse: 2.07895e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's rmse: 2.09512e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's rmse: 2.09911e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's rmse: 2.10843e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's rmse: 2.12315e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's rmse: 2.12703e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's rmse: 2.14206e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's rmse: 2.15091e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's rmse: 2.15949e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's rmse: 2.17607e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's rmse: 2.17237e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's rmse: 2.17771e+06\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 1.8026e+06\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 322\n",
      "[LightGBM] [Info] Number of data points in the train set: 103, number of used features: 43\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4478220.825243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's rmse: 2.16802e+06\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's rmse: 2.14334e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's rmse: 2.10386e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's rmse: 2.08321e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's rmse: 2.04334e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's rmse: 2.03061e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's rmse: 1.99795e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's rmse: 1.98953e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's rmse: 1.95096e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's rmse: 1.93013e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's rmse: 1.92036e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's rmse: 1.88651e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's rmse: 1.86807e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's rmse: 1.86149e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's rmse: 1.84792e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's rmse: 1.82835e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's rmse: 1.81813e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's rmse: 1.81142e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's rmse: 1.78707e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's rmse: 1.79122e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's rmse: 1.78663e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's rmse: 1.78209e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's rmse: 1.78935e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's rmse: 1.79463e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's rmse: 1.79737e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's rmse: 1.77727e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's rmse: 1.7743e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's rmse: 1.78044e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's rmse: 1.78044e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's rmse: 1.78023e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's rmse: 1.78171e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's rmse: 1.78069e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's rmse: 1.76733e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's rmse: 1.77157e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's rmse: 1.76445e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's rmse: 1.7665e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's rmse: 1.76724e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's rmse: 1.76822e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's rmse: 1.77442e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's rmse: 1.7674e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's rmse: 1.77986e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's rmse: 1.77628e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's rmse: 1.77912e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's rmse: 1.78e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's rmse: 1.77518e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's rmse: 1.78797e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's rmse: 1.78453e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's rmse: 1.78858e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's rmse: 1.79322e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's rmse: 1.80588e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's rmse: 1.80321e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's rmse: 1.80741e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's rmse: 1.80939e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's rmse: 1.81198e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's rmse: 1.81762e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's rmse: 1.81992e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's rmse: 1.81752e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's rmse: 1.80597e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's rmse: 1.81088e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's rmse: 1.80755e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's rmse: 1.80968e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's rmse: 1.81472e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's rmse: 1.82805e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's rmse: 1.82599e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's rmse: 1.83087e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's rmse: 1.83411e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's rmse: 1.83181e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's rmse: 1.84598e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's rmse: 1.84499e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's rmse: 1.84959e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's rmse: 1.83477e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's rmse: 1.84563e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's rmse: 1.85063e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's rmse: 1.85569e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's rmse: 1.84303e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's rmse: 1.84612e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's rmse: 1.83968e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's rmse: 1.83935e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's rmse: 1.85264e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's rmse: 1.8511e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's rmse: 1.86083e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's rmse: 1.86635e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's rmse: 1.8556e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's rmse: 1.85893e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's rmse: 1.85889e+06\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's rmse: 1.76445e+06\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 103, number of used features: 43\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4399369.106796\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's rmse: 3.14304e+06\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's rmse: 3.14391e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's rmse: 3.14931e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's rmse: 3.12084e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's rmse: 3.13042e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's rmse: 3.10788e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's rmse: 3.09807e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's rmse: 3.07727e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's rmse: 3.10154e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's rmse: 3.08553e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's rmse: 3.10108e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's rmse: 3.0977e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's rmse: 3.11715e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's rmse: 3.12319e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's rmse: 3.13123e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's rmse: 3.13968e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's rmse: 3.14734e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's rmse: 3.14997e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's rmse: 3.15804e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's rmse: 3.16529e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's rmse: 3.16566e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's rmse: 3.16715e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's rmse: 3.17777e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's rmse: 3.1807e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's rmse: 3.1825e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's rmse: 3.16721e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's rmse: 3.17427e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's rmse: 3.1756e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's rmse: 3.16777e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's rmse: 3.17083e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's rmse: 3.17458e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's rmse: 3.17629e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's rmse: 3.1772e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's rmse: 3.1804e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's rmse: 3.17079e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's rmse: 3.16845e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's rmse: 3.17204e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's rmse: 3.16572e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's rmse: 3.16368e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's rmse: 3.16646e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's rmse: 3.16498e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's rmse: 3.16768e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's rmse: 3.16877e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's rmse: 3.17103e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's rmse: 3.17937e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's rmse: 3.17805e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's rmse: 3.18622e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's rmse: 3.1923e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's rmse: 3.19078e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's rmse: 3.18399e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's rmse: 3.17657e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's rmse: 3.16935e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's rmse: 3.16807e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's rmse: 3.17029e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's rmse: 3.17098e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's rmse: 3.17275e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's rmse: 3.16954e+06\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's rmse: 3.16118e+06\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 3.07727e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plantator/miniconda3/envs/tf/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/plantator/miniconda3/envs/tf/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/plantator/miniconda3/envs/tf/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/plantator/miniconda3/envs/tf/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3696177.99325001 3912389.51264069 3848480.40382389 ... 5068819.43735508\n",
      " 4748719.75528779 5046260.13008347]\n"
     ]
    }
   ],
   "source": [
    "pred_train_1d =  train_model_and_predict(model_1d, df_trainval, y_trainval)\n",
    "pred_test_1d = predict(model_1d, df_trainval, df_test)\n",
    "print(pred_test_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN mean_absolute_error: 1608334.7431\n",
      "MLP mean_absolute_error: 4453532.6131\n",
      "RandomForest mean_absolute_error: 1670680.2016\n",
      "LightGBM mean_absolute_error: 1560284.4391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.608335e+06</td>\n",
       "      <td>1.670680e+06</td>\n",
       "      <td>1.560284e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            KNN            RF          LGBM\n",
       "0  1.608335e+06  1.670680e+06  1.560284e+06"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f'KNN mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1a):.4f}')\n",
    "print(f'MLP mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1b):.4f}')\n",
    "print(f'RandomForest mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1c):.4f}')\n",
    "print(f'LightGBM mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1d):.4f}')\n",
    "\n",
    "stat = pd.DataFrame({\n",
    "    'KNN':mean_absolute_error(y_trainval,pred_train_1a), \n",
    "    'RF':mean_absolute_error(y_trainval,pred_train_1c),\n",
    "    'LGBM':mean_absolute_error(y_trainval,pred_train_1d)}, index=[0])\n",
    "stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred_1a       pred_1c       pred_1d\n",
      "0    4387956.4  5.088421e+06  4.750886e+06\n",
      "1    3748290.6  4.020149e+06  3.735571e+06\n",
      "2    2770073.6  2.207294e+06  2.775671e+06\n",
      "3    3709546.8  4.493500e+06  4.438892e+06\n",
      "4    4463845.2  3.684721e+06  2.670208e+06\n",
      "..         ...           ...           ...\n",
      "132  3441556.6  3.680517e+06  3.831758e+06\n",
      "133  5667006.2  5.506136e+06  6.062351e+06\n",
      "134  3604085.6  3.679488e+06  3.788841e+06\n",
      "135  4674186.2  5.466908e+06  4.989295e+06\n",
      "136  5447667.0  6.654010e+06  5.762310e+06\n",
      "\n",
      "[137 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a,\n",
    "                          'pred_1c': pred_train_1c,\n",
    "                          'pred_1d': pred_train_1d,\n",
    "                         })\n",
    "test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a,\n",
    "                          'pred_1c': pred_test_1c,\n",
    "                          'pred_1d': pred_test_1d,\n",
    "                         })\n",
    "print(train_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_train_2 = train_model_and_predict(model2, train_x_2, y_trainval)\n",
    "pred_test_2 = predict(model2, df_trainval, test_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 1623166.3113\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_absolute_error: {mean_absolute_error(y_trainval, pred_train_2):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Prediction':pred_test_2})\n",
    "# submission = pd.DataFrame({'Id':df_test['Id'],'Prediction':pred_test_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission3.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
